{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Imports\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "from functools import reduce\n",
    "import json\n",
    "import numpy\n",
    "import re\n",
    "from styleframe import StyleFrame, Styler, utils\n",
    "import csv\n",
    "import time\n",
    "import pycountry\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x = pycountry.countries.get(alpha_2='KR')\n",
    "# print(x)\n",
    "# exit()\n",
    "# #Vietnam\n",
    "\n",
    "\n",
    "#Defining Paths\n",
    "main_path = os.getcwd()\n",
    "output_path = main_path + \"/Output/\"\n",
    "production_ouput_path = main_path + \"/Production_Output/\"\n",
    "shortlist_output_path = main_path + \"/Shortlist_Output/\"\n",
    "shortlist_production_ouput_path = main_path + \"/Shortlist_Production_Output/\"\n",
    "quarterly_path = main_path + \"/Quarterly_Insights/\"\n",
    "imputed_quarterly_path = main_path + \"/Imputed_Quarterly_Insights/\"\n",
    "#Change Here\n",
    "#Uncomment Change input\n",
    "input_path_treasury = main_path + \"/TREASURY_SPREADS_AND_YIELDS/\"  #/TREASURY_SPREADS_AND_YIELDS/ #BONDS_TO_SCRAPE_THRICE_INSTEAD_OF_TWICE\n",
    "if not os.path.exists('Output'):\n",
    "      os.makedirs('Output')\n",
    "if not os.path.exists('Production_Output'):\n",
    "      os.makedirs('Production_Output')\n",
    "if not os.path.exists('Shortlist_Output'):\n",
    "      os.makedirs('Shortlist_Output')\n",
    "if not os.path.exists('Shortlist_Production_Output'):\n",
    "      os.makedirs('Shortlist_Production_Output')\n",
    "if not os.path.exists('Quarterly_Insights'):\n",
    "      os.makedirs('Quarterly_Insights')\n",
    "if not os.path.exists(\"Imputed_Quarterly_Insights\"):\n",
    "      os.makedirs(\"Imputed_Quarterly_Insights\")\n",
    "\n",
    "\n",
    "#Change Here Renaming Conflict Names\n",
    "os.chdir(input_path_treasury)\n",
    "try:\n",
    "  os.rename(r'Souht Africa 12 Year Bond Yield Historical Data (2).csv',r'South Africa 12-Year Bond Yield Historical Data (2).csv')\n",
    "  os.rename(r'Souht Africa 12 Year Bond Yield Historical Data (1).csv',r'South Africa 12-Year Bond Yield Historical Data (1).csv')\n",
    "  os.rename(r'Souht Africa 12 Year Bond Yield Historical Data.csv',r'South Africa 12-Year Bond Yield Historical Data.csv')\n",
    "except:\n",
    "  print(\"Already Renamed South Africa\")\n",
    "try:\n",
    "  os.rename(r'U.S. 20-Year Bond Yield Bond Yield Historical Data (2).csv',r'United States 20-Year Bond Yield Historical Data (2).csv')\n",
    "  os.rename(r'U.S. 20-Year Bond Yield Bond Yield Historical Data (1).csv',r'United States 20-Year Bond Yield Historical Data (1).csv')\n",
    "  os.rename(r'U.S. 20-Year Bond Yield Bond Yield Historical Data.csv',r'United States 20-Year Bond Yield Historical Data.csv')\n",
    "except:\n",
    "  print(\"Already Renamed\")\n",
    "try:\n",
    "  os.rename(r'Canada 10-Year Bond Yield Historical Data (3).csv',r'Canada 10-Year Bond Yield Historical Data.csv')\n",
    "except:\n",
    "  print(\"Already Renamed\")\n",
    "\n",
    "os.chdir(main_path)\n",
    "\n",
    "#Extensions\n",
    "csv_extension = 'csv'\n",
    "xlsx_extension =\"xlsx\"\n",
    "\n",
    "#Global Var\n",
    "os.chdir(main_path)\n",
    "os.chdir(input_path_treasury)\n",
    "countryNames = glob.glob('*.{}'.format(csv_extension))\n",
    "os.chdir(main_path)\n",
    "dataDictd = []\n",
    "dataDictx = []\n",
    "\n",
    "#Short Funcs\n",
    "def atoi(text):\n",
    "        return (int(text) if text.isdigit() else text)\n",
    "def natural_keys(text):\n",
    "        return [ atoi(c) for c in re.split('(\\d+)',text) ]\n",
    "def writeToCsv(input_list,name):\n",
    "  os.chdir(main_path)\n",
    "  os.chdir(production_ouput_path)\n",
    "  f = open(name, 'a+',newline='')\n",
    "  with f:\n",
    "        writer = csv.writer(f)\n",
    "        # writer.writerow([\"Name\", \"Abbreviation\"])\n",
    "        writer.writerows(input_list)\n",
    "  os.chdir(main_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Function To Create adict.csv file containing starting and ending date.\n",
    "#Change here\n",
    "def createADic():\n",
    "    global countryNames\n",
    "    \n",
    "    os.chdir(main_path)\n",
    "    \n",
    "    countryNames.sort(key=natural_keys)\n",
    "    # print(countryNames)\n",
    "    # exit()\n",
    "\n",
    "    os.chdir(output_path)\n",
    "    f = open('adict.csv', 'w',newline='')\n",
    "    with f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"Countries\",\"1st starting date\",\"1st ending date\",\"2nd starting date\",\"2nd ending date\",\n",
    "        \"3rd starting date\",\"3rd ending date\"\n",
    "        ])\n",
    "    os.chdir(input_path_treasury)\n",
    "\n",
    "    rowToWrite = []\n",
    "    rowOfrows = []\n",
    "    count = 0\n",
    "    for countryName in countryNames:\n",
    "        count += 1\n",
    "        if count == 4:\n",
    "            rowOfrows.append(rowToWrite)\n",
    "            rowToWrite = []\n",
    "            count = 1\n",
    "        if count < 4:\n",
    "            rowList = []\n",
    "            with open(countryName, newline='', encoding='latin-1') as f: \n",
    "                reader = csv.reader(f)\n",
    "                for row in reader:\n",
    "                    rowList.append(row)\n",
    "\n",
    "            try:\n",
    "                endDate = rowList[1][0]\n",
    "                startDate = rowList[-1][0]\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if count == 1:\n",
    "                rowToWrite.insert(0,countryName.replace(\" (1)\", \"\"))\n",
    "                rowToWrite.insert(5,startDate)\n",
    "                rowToWrite.insert(6,endDate)\n",
    "\n",
    "            elif count == 2:\n",
    "                rowToWrite.insert(1,startDate)\n",
    "                rowToWrite.insert(2,endDate)\n",
    "\n",
    "            else:\n",
    "            \n",
    "                rowToWrite.insert(1,startDate)\n",
    "                rowToWrite.insert(2,endDate)\n",
    "            \n",
    "        \n",
    "            \n",
    "                \n",
    "\n",
    "        \n",
    "\n",
    "            \n",
    "        if countryNames.index(countryName)==len(countryNames)-1:\n",
    "            \n",
    "            rowOfrows.append(rowToWrite)\n",
    "        \n",
    "    os.chdir(main_path)\n",
    "    os.chdir(output_path)\n",
    "    f = open('adict.csv', 'a+',newline='')\n",
    "    with f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rowOfrows)\n",
    "    os.chdir(main_path)\n",
    "\n",
    "\n",
    "# p = input(\"Do you want to create adic.csv ? Enter y/n  \")\n",
    "# if p == \"y\":\n",
    "#Uncomment\n",
    "createADic()\n",
    "\n",
    "\n",
    "\n",
    "def getCountryAbbr(input_country):\n",
    "    countries = {}\n",
    "    for country in pycountry.countries:\n",
    "          countries[country.name] = country.alpha_2\n",
    "      \n",
    "    if input_country == \"Vietnam\":\n",
    "      input_country = \"Viet Nam\"\n",
    "    elif input_country == \"Czech Republic\":\n",
    "      input_country = \"Czechia\"\n",
    "    elif input_country == \"Russia\":\n",
    "      input_country = \"Russian Federation\"\n",
    "    elif input_country == \"South Korea\":\n",
    "      input_country = \"Korea, Republic of\"\n",
    "    elif input_country == \"Taiwan\":\n",
    "      input_country = \"Taiwan, Province of China\"\n",
    "    code = countries.get(input_country, 'Unknown code')\n",
    "    return code\n",
    "\n",
    "\n",
    "def renameCountry(input_name,over):\n",
    "        # print(input_name,\"------\")   \n",
    "        if \"Treasury Spread\" in input_name and \"Overnight\" not in input_name:\n",
    "\n",
    "            # print(input_name,\"---------\")\n",
    "            x = re.search(\"Of (.+)_(.+) (\\d+)-*(.+) Over\", input_name)\n",
    "            # print(x.group(1)[0],\"..............\")\n",
    "            field = x.group(1)[0]\n",
    "            country = getCountryAbbr(x.group(2))\n",
    "            yearOrmonthVal = x.group(3)\n",
    "            yearOrmonth = x.group(4)[0]\n",
    "            a = re.search(\"(\\d+)-*(.+) \",over)\n",
    "            overYear = a.group(2)[0]\n",
    "            overYearVal = a.group(1)\n",
    "\n",
    "            \n",
    "\n",
    "            output = \"{0}_{1}_TS{2}{3}B_VS_{4}{5}B\".format(country,field,yearOrmonthVal,yearOrmonth,overYearVal,overYear)\n",
    "            #SAMPLE OUTPUT Unknown code_P_TS1YB_VS_1YB\n",
    "            return output\n",
    "        #Change Here\n",
    "        elif \"Overnight\" in input_name and \"Treasury Spread\" in input_name:\n",
    "            x = re.search(\"Of (.+)_(.+) (\\d+)-*(.+) Over Overnight\", input_name)\n",
    "            \n",
    "            field = x.group(1)[0]\n",
    "            country = getCountryAbbr(x.group(2))\n",
    "            yearOrmonthVal = x.group(3)\n",
    "            yearOrmonth = x.group(4)[0]\n",
    "            if \"Overnight\" not in over:\n",
    "              a = re.search(\"(\\d+)-*(.+) \",over)\n",
    "              print(input_name)\n",
    "              print(over)\n",
    "              print(a)\n",
    "              overYear = a.group(2)[0]\n",
    "              overYearVal = a.group(1)\n",
    "            else:\n",
    "              overYear = \"V\"\n",
    "              overYearVal = \"O\"\n",
    "\n",
    "            output = \"{0}_{1}_TS{4}{5}B_VS_{2}{3}B\".format(country,field,overYearVal,overYear,yearOrmonthVal,yearOrmonth)\n",
    "            return output\n",
    "        elif \"Overnight\" in input_name and \"Treasury Spread\" not in input_name:\n",
    "            x = re.search(\"(.+)_(.+) Overnight\", input_name)\n",
    "            field = x.group(1)[0]\n",
    "            country = getCountryAbbr(x.group(2))\n",
    "\n",
    "            output = \"{0}_{1}_TYOVB\".format(country,field)\n",
    "            return output\n",
    "        else:\n",
    "            x = re.search(\"(.+)_(.+) (\\d+)-*(.+)\", input_name)\n",
    "            field = x.group(1)[0]\n",
    "            country = getCountryAbbr(x.group(2))\n",
    "            yearOrmonthVal = x.group(3)\n",
    "            yearOrmonth = x.group(4)[0]\n",
    "            output = \"{0}_{1}_TY{2}{3}B\".format(country,field,yearOrmonthVal,yearOrmonth)\n",
    "            return output\n",
    "\n",
    "\n",
    "def globalRename(df1,df2,inc):\n",
    "  global dataDictd\n",
    "  global dataDictx\n",
    "\n",
    "  over = df1.columns[1+inc]\n",
    "  renamed = []\n",
    "  renamex = []\n",
    "  for i in df2.columns[1:]:\n",
    "    ans = renameCountry(i,over)\n",
    "    dataDictd.append([i,ans])\n",
    "    renamed.append(ans)\n",
    "  for i in df1.columns[1:]:\n",
    "    ans = renameCountry(i,over)\n",
    "    renamex.append(ans)\n",
    "    dataDictx.append([i,ans])\n",
    "  \n",
    "  renamed.insert(0,\"Date\")\n",
    "  renamex.insert(0,\"Date\")\n",
    "  \n",
    "  copy_df1 = df1.copy(deep=True)\n",
    "  copy_df2 = df2.copy(deep=True)\n",
    "\n",
    "  copy_df1.columns = renamex\n",
    "  copy_df2.columns = renamed\n",
    "  return copy_df1,copy_df2\n",
    "\n",
    "def globalRename_withoutIndex(df1,df2,inc):\n",
    "  short_dataDic = []\n",
    "  short_dataDictx = []\n",
    "  # print(df1)\n",
    "  # print(df2)\n",
    "  over = df1.columns[0+inc]\n",
    "  # print(over, inc)\n",
    "  # exit()\n",
    "  renamed = []\n",
    "  renamex = []\n",
    "  for i in df2.columns[0:]:\n",
    "    ans = renameCountry(i,over)\n",
    "    short_dataDic.append([i,ans])\n",
    "    renamed.append(ans)\n",
    "  for i in df1.columns[0:]:\n",
    "    ans = renameCountry(i,over)\n",
    "    renamex.append(ans)\n",
    "    short_dataDictx.append([i,ans])\n",
    "  \n",
    "  \n",
    "  copy_df1 = df1.copy(deep=True)\n",
    "  copy_df2 = df2.copy(deep=True)\n",
    "\n",
    "  copy_df1.columns = renamex\n",
    "  copy_df2.columns = renamed\n",
    "  return copy_df1,copy_df2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def sortByDate(result):\n",
    "  result = result.reset_index()\n",
    "  result['Date'] =pd.to_datetime(result.Date)\n",
    "  sorted_df = result.sort_values(by='Date',axis=0,ascending=False)\n",
    "  sorted_df[\"Date\"]=sorted_df.Date.dt.strftime('%b %d, %y')\n",
    "  return sorted_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#---------------Fucntions Inside\n",
    "def extractingTreasurySpreads(bonds,inc):\n",
    "  \n",
    "  c=0\n",
    "  \n",
    "  \n",
    "  print(len(bonds))\n",
    "  #Change Here  alsi check .csv in final name\n",
    "  for x in range(0,len(bonds)):\n",
    "        if x == 0:\n",
    "          # currNum = dd[key][x+(3+inc)]\n",
    "          #currNum = dd[key][x+(3+inc)+2]\n",
    "          currNum = dd[key][5+(inc*3)]\n",
    "          # againstNum = dd[key][(x+(3+inc)-2)].split(\" \")[-5]\n",
    "          againstNum = dd[key][5+(inc*3)-3].split(\" \")[-5]\n",
    "          bonds[x] = bonds[x].rename(columns={'Price':'Treasury Spread Of Price_{0} Over {1} Bond Yeild'.format(currNum,againstNum),\n",
    "            'Change %':'Treasury Spread Of Change %_{0} Over {1} Bond Yeild'.format( currNum,againstNum),\n",
    "            'High':'Treasury Spread Of High_{0} Over {1} Bond Yeild'.format(currNum,againstNum),\n",
    "            'Low':'Treasury Spread Of Low_{0} Over {1} Bond Yeild'.format(currNum,againstNum),\n",
    "            'Open':'Treasury Spread Of Open_{0} Over {1} Bond Yeild'.format(currNum,againstNum)\n",
    "                                })\n",
    "          # c = x+(3+inc) \n",
    "          # c = x+(3+inc) + 2\n",
    "          c = 5+(inc*3)\n",
    "        \n",
    "        \n",
    "\n",
    "        else:\n",
    "          # new = c+2\n",
    "          new = c+3\n",
    "          news = dd[key][new]\n",
    "          # agains = dd[key][inc+1].split(\" \")[-5]\n",
    "          agains = dd[key][2+(3*inc)].split(\" \")[-5]\n",
    "\n",
    "         \n",
    "          print(news,\"from\")\n",
    "          print(agains,\"against\")\n",
    "          \n",
    "          bonds[x] = bonds[x].rename(columns={'Price':'Treasury Spread Of Price_{0} Over {1} Bond Yeild'.format(dd[key][new],agains),\n",
    "            'Change %':'Treasury Spread Of Change %_{0} Over {1} Bond Yeild'.format(dd[key][new], agains),\n",
    "            'High':'Treasury Spread Of High_{0} Over {1} Bond Yeild'.format(dd[key][new],agains),\n",
    "            'Low':'Treasury Spread Of Low_{0} Over {1} Bond Yeild'.format(dd[key][new],agains),\n",
    "            'Open':'Treasury Spread Of Open_{0} Over {1} Bond Yeild'.format(dd[key][new],agains)\n",
    "                                })\n",
    "          c = new\n",
    "  # print(bonds)\n",
    "  # exit()\n",
    "  \n",
    "      \n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "  \n",
    "\n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "  if len(bonds) == 2:\n",
    "    result = pd.merge(bonds[0],bonds[1],on=[\"Date\"] , how=\"outer\")\n",
    "    result = result[~result.index.duplicated()]\n",
    "    result = result.fillna(value=\"na\")\n",
    "    \n",
    "  elif len(bonds) == 1:\n",
    "    result = bonds[0]\n",
    "  else:\n",
    "    \n",
    "    result = ''\n",
    "    for i in range(0,len(bonds)):  #for i in range(0,len(bonds),2):\n",
    "      \n",
    "      if i == 0:\n",
    "        result = pd.merge(bonds[i],bonds[i+1],on=[\"Date\"] , how=\"outer\")\n",
    "        result = result[~result.index.duplicated()]\n",
    "        result = result.fillna(value=\"na\")\n",
    "      elif i == 1:\n",
    "        continue\n",
    "      else:\n",
    "        result = pd.merge(result,bonds[i], on=[\"Date\"] , how=\"outer\")\n",
    "        result = result[~result.index.duplicated()]\n",
    "        result = result.fillna(value=\"na\")\n",
    "  \n",
    "  #Rearranging Columns\n",
    "  x = result.columns[0:-1:5]\n",
    "  y = result.columns[1:-1:5]\n",
    "  z = result.columns[2:-1:5]\n",
    "  a = result.columns[3:-1:5]\n",
    "  b = result.columns[4::5]\n",
    "  \n",
    "  xy = list(x)+list(y)+list(z)+list(a)+list(b)\n",
    "  result = result[xy]\n",
    "\n",
    "\n",
    "  #Sorting Columns By Date\n",
    "  sorted_df = sortByDate(result)\n",
    "  print(sorted_df,\"...............................................\")\n",
    "\n",
    " \n",
    "  sorted_df.columns = sorted_df.columns.str.replace('.csv', '')\n",
    "\n",
    "  return result,sorted_df\n",
    "\n",
    "def extractingTreasuryYeilds(nbonds):\n",
    "  bonxs = [i for i in nbonds]\n",
    "  print(len(bonxs))\n",
    "  c=0\n",
    "  #Change Here\n",
    "  for x in range(0,len(bonxs)):\n",
    "        if x == 0:\n",
    "          #[x+1]\n",
    "          bonxs[x] = bonxs[x].rename(columns={'Price':'Price_{0}'.format(dd[key][x+2]),\n",
    "            'Change %':'Change %_{0}'.format(dd[key][x+2]),'High':'High_{0}'.format(dd[key][x+2]),\n",
    "            'Low':'Low_{0}'.format(dd[key][x+2]),'Open':'Open_{0}'.format(dd[key][x+2])\n",
    "                                })\n",
    "          # c = x+1\n",
    "          c = x+2\n",
    "        else:\n",
    "          # new = c+2\n",
    "          new = c+3\n",
    "          bonxs[x] = bonxs[x].rename(columns={'Price':'Price_{0}'.format(dd[key][new]),\n",
    "            'Change %':'Change %_{0}'.format(dd[key][new]),'High':'High_{0}'.format(dd[key][new]),\n",
    "            'Low':'Low_{0}'.format(dd[key][new]),'Open':'Open_{0}'.format(dd[key][new])\n",
    "                                })\n",
    "          c = new\n",
    "        # print(bonxs[x])\n",
    "        # exit()\n",
    "  \n",
    "  \n",
    "\n",
    "  if len(bonxs) == 2:\n",
    "    # resulx = pd.DataFrame.drop_duplicates(pd.merge(bonxs[0],bonxs[1],on=[\"Date\"] , how=\"outer\"))\n",
    "    resulx = pd.merge(bonxs[0],bonxs[1],on=[\"Date\"] , how=\"outer\")\n",
    "    resulx = resulx[~resulx.index.duplicated()]\n",
    "    \n",
    "  elif len(bonxs) == 1:\n",
    "    resulx = bonxs[0]\n",
    "  else:\n",
    "    \n",
    "    resulx = ''\n",
    "    for i in range(0,len(bonxs)):\n",
    "      \n",
    "      if i == 0:\n",
    "        resulx = pd.merge(bonxs[i],bonxs[i+1],on=[\"Date\"] , how=\"outer\")\n",
    "        resulx = resulx[~resulx.index.duplicated()]\n",
    "      elif i == 1:\n",
    "        continue\n",
    "      else:        \n",
    "        resulx = pd.merge(resulx,bonxs[i], on=[\"Date\"] , how=\"outer\")\n",
    "        resulx = resulx[~resulx.index.duplicated()]\n",
    "  \n",
    "  b = resulx.columns[:]\n",
    "  \n",
    "  resulx[b] =  resulx[b].fillna(value=\"na\")\n",
    "\n",
    "  x = resulx.columns[0:-1:5]\n",
    "  y = resulx.columns[1:-1:5]\n",
    "  z = resulx.columns[2:-1:5]\n",
    "  a = resulx.columns[3:-1:5]\n",
    "  b = resulx.columns[4::5]\n",
    "  \n",
    "  xy = list(x)+list(y)+list(z)+list(a)+list(b)\n",
    "  \n",
    "  resulx = resulx[xy]\n",
    "  sortex_df = sortByDate(resulx)\n",
    "\n",
    "  \n",
    "  sortex_df.columns = sortex_df.columns.str.replace('.csv', '')\n",
    "\n",
    "  return resulx,sortex_df\n",
    "\n",
    "\n",
    "def shortlistedYeild(resulx):\n",
    "    y = len(list(resulx.columns))/5\n",
    "    x = resulx.columns[0:int(y)]\n",
    "    xy = list(x)\n",
    "    mod_resulx = resulx[xy]\n",
    "    shortlist_sortex_df = sortByDate(mod_resulx)\n",
    "    shortlist_sortex_df.columns = shortlist_sortex_df.columns.str.replace('.csv', '')\n",
    "    #print(shortlist_sortex_df, \"chcek\")\n",
    "    #Almost done\n",
    "    return shortlist_sortex_df\n",
    "\n",
    "def shortlistedSpread(result):\n",
    "\n",
    "    #---------For Spread\n",
    "    # x = result.columns[0:-1:5]\n",
    "    y = len(list(result.columns))/5\n",
    "    x = result.columns[0:int(y)]\n",
    "    xy = list(x)\n",
    "    mod_result = result[xy]\n",
    "   \n",
    "    neg_mod_result = mod_result.replace(\"na\",0)\n",
    "    neg_mod_result = neg_mod_result.mask(neg_mod_result >= 0, 0)\n",
    "    neg_mod_result = neg_mod_result.mask(neg_mod_result < 0, 1)\n",
    "    #Renaming Column  Name\n",
    "    neg_mod_result=neg_mod_result.add_prefix(\"Incidences Of Negative \")\n",
    "    \n",
    "    final_mod_result = pd.concat([mod_result, neg_mod_result], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "    shortlist_sorted_df = sortByDate(final_mod_result)\n",
    "    shortlist_sorted_df.columns = shortlist_sorted_df.columns.str.replace('.csv', '')\n",
    "    print(shortlist_sorted_df)\n",
    "    return shortlist_sorted_df\n",
    "\n",
    "\n",
    "#UNCOMMENT\n",
    "#Working here! Problems....\n",
    "def quarterlyInsightsYeild(resulx , tempdf2, inc):\n",
    "    # x = resulx.columns[0:-1:5]\n",
    "    y = len(list(resulx.columns))/5\n",
    "    x = resulx.columns[0:int(y)]\n",
    "    # print(resulx.columns)\n",
    "    # exit()\n",
    "    xy = list(x)\n",
    "    price_resulx = resulx[xy]\n",
    "    price_resulx.columns =  price_resulx.columns.str.replace('.csv', '')\n",
    "    price_resulx = price_resulx.replace(\"na\",numpy.nan)\n",
    "    \n",
    "    date_resulx = price_resulx.reset_index()\n",
    "    date_resulx['Date'] =pd.to_datetime(date_resulx.Date)\n",
    "    date_sortex_df = date_resulx.sort_values(by='Date',axis=0,ascending=False)\n",
    "    date_sortex_df = date_sortex_df.set_index(\"Date\")\n",
    "\n",
    "    \n",
    "\n",
    "    get_negatives.__name__ = \"Number Of Negative Incidences\"\n",
    "    date_sortex_df = date_sortex_df.resample(\"QS\").agg(['mean',\"last\"]) #drop na = True\n",
    "\n",
    "    \n",
    "    print(price_resulx,\"000000000000000000\")\n",
    "    a, b= globalRename_withoutIndex(price_resulx,tempdf2, inc)\n",
    "    \n",
    "\n",
    "    #GETTING COLUMN NAMES Yeilds\n",
    "    col_names_a=[]\n",
    "\n",
    "    a = list(a)\n",
    "    co = 0\n",
    "    for i in range(0,len(a)*2,2):\n",
    "      renam = \"Average_TY_\"+a[int(co)]\n",
    "      renam2 = \"End_Of_Quarter_TY_\"+a[int(co)]\n",
    "      col_names_a.append(renam)\n",
    "      col_names_a.append(renam2)\n",
    "      co+=1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    date_sortex_df.columns = col_names_a\n",
    "    \n",
    "    #------------- Fill Na and Set Date\n",
    "    \n",
    "    mod_date_sortex_df = date_sortex_df.fillna(\"na\")\n",
    "    mod_date_sortex_df = mod_date_sortex_df.reset_index()\n",
    "    mod_date_sortex_df[\"Date\"]=mod_date_sortex_df.Date.dt.strftime('%b %d, %y')\n",
    "\n",
    "\n",
    "    print(mod_date_sortex_df)\n",
    "\n",
    "    return mod_date_sortex_df, price_resulx, date_sortex_df\n",
    "\n",
    "\n",
    "\n",
    "def quarterlyInsightsSpread(result,price_resulx,date_sortex_df, inc):\n",
    "    y = len(list(result.columns))/5\n",
    "    x = result.columns[0:int(y)]\n",
    "    #x = result.columns[0:-1:5]\n",
    "    # print(x)\n",
    "    # exit()\n",
    "    xy = list(x)\n",
    "    price_result = result[xy]\n",
    "    price_result.columns =  price_result.columns.str.replace('.csv', '')\n",
    "    price_result = price_result.replace(\"na\",numpy.nan)\n",
    "\n",
    "    date_result = price_result.reset_index()\n",
    "    date_result['Date'] =pd.to_datetime(date_result.Date)\n",
    "    date_sorted_df = date_result.sort_values(by='Date',axis=0,ascending=False)\n",
    "    date_sorted_df = date_sorted_df.set_index(\"Date\")\n",
    "\n",
    "\n",
    "    date_sorted_df = date_sorted_df.resample(\"QS\").agg(['mean',\"last\",get_negatives,\"min\"]) #drop na = True\n",
    "\n",
    "    print(price_resulx,\"000000000000000000\")\n",
    "    a, b= globalRename_withoutIndex(price_resulx,price_result, inc)\n",
    "    \n",
    "\n",
    "    #GETTING COLUMN NAMES Yeilds\n",
    "    col_names_a=[]\n",
    "    col_names_b = []\n",
    "\n",
    "    a = list(a)\n",
    "    co = 0\n",
    "    for i in range(0,len(a)*2,2):\n",
    "      renam = \"Average_TY_\"+a[int(co)]\n",
    "      renam2 = \"End_Of_Quarter_TY_\"+a[int(co)]\n",
    "      col_names_a.append(renam)\n",
    "      col_names_a.append(renam2)\n",
    "      co+=1\n",
    "\n",
    "    b = list(b)\n",
    "    co =0\n",
    "    for i in range(0,len(b)):\n",
    "      renam = \"Average_SPD_\"+b[i]\n",
    "      renam2 = \"End_Of_Quarter_SPD_\"+b[i]\n",
    "      renam3 = \"No_Of_Negative_SPD_\"+b[i]\n",
    "      renam4 = \"Min_SPD_\"+b[i]\n",
    "      col_names_b.append(renam)\n",
    "      col_names_b.append(renam2)\n",
    "      col_names_b.append(renam3)\n",
    "      col_names_b.append(renam4)\n",
    "\n",
    "    \n",
    "      print()\n",
    "\n",
    "    date_sortex_df.columns = col_names_a\n",
    "    date_sorted_df.columns = col_names_b\n",
    "    \n",
    "    #------------- Fill Na and Set Date\n",
    "    \n",
    "\n",
    "    mod_date_sorted_df = date_sorted_df.fillna(\"na\")\n",
    "    mod_date_sorted_df = mod_date_sorted_df.reset_index()\n",
    "    mod_date_sorted_df[\"Date\"]=mod_date_sorted_df.Date.dt.strftime('%b %d, %y')\n",
    "\n",
    "\n",
    "    print(mod_date_sorted_df)\n",
    "    \n",
    "\n",
    "    return mod_date_sorted_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def ImputedYeild(mod_date_sortex_df):\n",
    "    imputed_yeild_df = mod_date_sortex_df.replace(\"na\",numpy.nan).fillna(method='ffill').fillna(\"na\")\n",
    "    return imputed_yeild_df\n",
    "\n",
    "\n",
    "def ImputedSpread(imputed_yeild_df, mod_date_sorted_df,inc):\n",
    "  \n",
    "\n",
    "    ### SPREADS ####\n",
    "    imput_y = imputed_yeild_df.replace('na',numpy.nan)\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    x = imput_y.columns[1::2]\n",
    "    y = imput_y.columns[2::2]\n",
    "\n",
    "    # print(x)\n",
    "    # print(y)\n",
    "    # exit()\n",
    "\n",
    "    avg = pd.DataFrame()\n",
    "\n",
    "    # count =0\n",
    "    # for i in list(x):\n",
    "    #   count+=1\n",
    "    #   if count == 1:\n",
    "        \n",
    "    #     continue\n",
    "    #   else:\n",
    "  \n",
    "        \n",
    "    #     avg[\"avg{0}\".format(count)] = imput_y[i] - imput_y.iloc[:,1]\n",
    "    # count =0\n",
    "    # inc  = 1\n",
    "    print(inc)\n",
    "    # exit()\n",
    "    count = 1\n",
    "    startFrom = 1 + inc\n",
    "    if inc == 0:\n",
    "      cc = 1\n",
    "    else: \n",
    "      cc = inc + 2\n",
    "    for i in range(startFrom, len(list(x))):\n",
    "      \n",
    "      \n",
    "      # print(imput_y[x[i]])\n",
    "      # print(imput_y.iloc[:,cc])\n",
    "      \n",
    "      \n",
    "      \n",
    "      avg[\"avg{0}\".format(count)] = imput_y[x[i]] - imput_y.iloc[:,cc]\n",
    "      count +=1\n",
    "    \n",
    "    # print(avg)\n",
    "    # exit()\n",
    "    \n",
    "    \n",
    "    end = pd.DataFrame()\n",
    "    count =1\n",
    "    if inc == 0:\n",
    "      cc = 2\n",
    "    else: \n",
    "      cc = inc + 2\n",
    "    for i in range(startFrom, len(list(y))):\n",
    "      \n",
    "        \n",
    "      end[\"end{0}\".format(count)] = imput_y[y[i]] - imput_y.iloc[:,cc] #mistake here\n",
    "      count += 1\n",
    "\n",
    "    avg_end = pd.merge(avg,end,left_index=True,right_index=True)\n",
    "    \n",
    "    # print(avg_end)\n",
    "    # exit()\n",
    "\n",
    "   \n",
    "    #Corrected Till Here\n",
    "\n",
    "              #Renaming Avg End\n",
    "    len_ae = len(avg_end.columns)/2\n",
    "    len_ae = int(len_ae)\n",
    "    z = mod_date_sorted_df.columns[1::4]\n",
    "    a = mod_date_sorted_df.columns[2::4]\n",
    "    \n",
    "    \n",
    "    naming = list(z)+list(a)\n",
    "\n",
    "    \n",
    "    print(avg_end)\n",
    "    print(naming)\n",
    "    \n",
    "    avg_end.columns = naming\n",
    "\n",
    "\n",
    "   \n",
    "    # print(avg_end)\n",
    "    # exit()\n",
    "\n",
    "    #Checked Till here\n",
    "\n",
    "    # mod_date_sorted_df means quartely insights spread\n",
    "\n",
    "    spreads_train = mod_date_sorted_df.replace(\"na\",numpy.nan)\n",
    "    yx =  spreads_train.columns[3::4]\n",
    "    xy =  spreads_train.columns[4::4]\n",
    "    min_neg = spreads_train[list(xy)+list(yx)]\n",
    "    print(min_neg)\n",
    "\n",
    "    imp_spread = pd.merge(avg_end,min_neg,left_index=True,right_index=True)\n",
    "\n",
    "    #imp_spread will be replaced with na at end\n",
    "\n",
    "\n",
    "    lst = []\n",
    "    for i in range(len_ae):\n",
    "\n",
    "      mod = imp_spread.columns[i::len_ae]\n",
    "      lst += list(mod)\n",
    "\n",
    "    print(lst)\n",
    "\n",
    "\n",
    "    imp_spread = imp_spread[lst]\n",
    "\n",
    " \n",
    "    # print(imp_spread)\n",
    "    # exit()\n",
    "\n",
    "    #Checked Till Here\n",
    "\n",
    "    #---------------------------------\n",
    "    #GET All Avg , turn na's to something else\n",
    "    colsAvg = imp_spread.columns[0::4]\n",
    "    AvgDf = imp_spread[list(colsAvg)]\n",
    "    AvgDf = AvgDf.fillna(\"Bypass\")\n",
    "    #print(AvgDf)\n",
    "    imp_spread[list(colsAvg)] = AvgDf\n",
    "\n",
    "\n",
    "    \n",
    "    # print(imp_spread)\n",
    "    # exit()\n",
    "\n",
    "    \n",
    "\n",
    "          #Fill NA Min\n",
    "    imp_spread = imp_spread.fillna(axis=1,limit=1,method=\"ffill\")\n",
    "    #Replace bypass\n",
    "    imp_spread = imp_spread.replace(\"Bypass\",numpy.nan)\n",
    "\n",
    "    imp_spread=imp_spread.replace(\"nan\",numpy.nan) #Uncomment Check\n",
    "\n",
    "    \n",
    "    # print(imp_spread)\n",
    "    # exit()\n",
    "\n",
    "    #Checked Problem Here\n",
    "    # Previous Neg filling val to next Avg\n",
    "\n",
    "          #NEg Jugaar\n",
    "    colNames = imp_spread.columns\n",
    "    listOfDFRows = imp_spread.to_numpy().tolist()\n",
    "    for currCol in range(1,len(listOfDFRows)):\n",
    "      for col in range(1,len(listOfDFRows[currCol])):\n",
    "          if math.isnan(listOfDFRows[currCol][col]):\n",
    "            if listOfDFRows[currCol][col-1] < 0:\n",
    "              listOfDFRows[currCol][col] = 1\n",
    "            elif listOfDFRows[currCol][col-1] > 0:\n",
    "              listOfDFRows[currCol][col] = 0\n",
    "\n",
    "    print(len(listOfDFRows))\n",
    "\n",
    "\n",
    "\n",
    "    imputed_spread = pd.DataFrame(listOfDFRows)\n",
    "    imputed_spread.columns = colNames\n",
    "\n",
    "    #Removing 0 from Avg\n",
    "    # \n",
    "    someColsFromDf = imputed_spread.columns[0::4]     \n",
    "    newDf = imputed_spread[list(someColsFromDf)]      \n",
    "    newDf = newDf.replace(0,numpy.nan)\n",
    "    imputed_spread[list(someColsFromDf)] = newDf\n",
    "\n",
    "    # pd.set_option('display.max_rows', 180)\n",
    "    # pd.set_option('display.max_columns', 20)\n",
    "    # print(imputed_spread)\n",
    "    # exit()\n",
    "\n",
    "\n",
    "          #Add Date Col\n",
    "    date = mod_date_sorted_df.columns[0]\n",
    "    date = mod_date_sorted_df[date]\n",
    "    imputed_spread.insert(0, \"Date\", date)\n",
    "\n",
    "    print(imputed_spread)\n",
    "\n",
    "        #Writing\n",
    "\n",
    "\n",
    "    final_spread_imputed_quartely = mod_date_sorted_df.copy(deep=True)\n",
    "    final_spread_imputed_quartely = final_spread_imputed_quartely.replace(\"na\",numpy.nan).replace(\"nan\",numpy.nan)\n",
    "    final_spread_imputed_quartely=final_spread_imputed_quartely.fillna(imputed_spread)\n",
    "    final_spread_imputed_quartely = final_spread_imputed_quartely.fillna(\"na\")\n",
    "\n",
    "    \n",
    "    print(final_spread_imputed_quartely)\n",
    "    return final_spread_imputed_quartely\n",
    "\n",
    "\n",
    "def addTSSheet(writer,dataframe,count):\n",
    "    dataframe.to_excel(writer,'Treasury Spread {0}'.format(count),index=False)\n",
    "\n",
    "def addTYSheet(writer,dataframe):\n",
    "    dataframe.to_excel(writer,'Merging By Date'.format(count),index=False)\n",
    "\n",
    "def get_negatives(x):\n",
    "      if sum(x<0)==0 and sum(x>0)==0:\n",
    "        return \"nan\" \n",
    "      else:\n",
    "        return sum(x<0)\n",
    "\n",
    "\n",
    "#Change Here Maybe\n",
    "countries =['Argentina', 'Australia', 'Austria', 'Bahrain', 'Bangladesh', 'Belgium', 'Botswana', 'Brazil', 'Bulgaria', 'Canada', 'Chile', 'China', 'Colombia', 'Croatia', \n",
    "'Cyprus', 'Czech', 'Egypt', 'France', 'Germany', 'Greece', 'Hong', 'Hungary', 'Iceland', 'India', 'Indonesia', 'Ireland', 'Israel', 'Italy', 'Japan', 'Jordan', 'Kenya',\n",
    " 'Malaysia', 'Malta', 'Mauritius', 'Mexico', 'Morocco', 'Namibia', 'Netherlands', 'New Zealand', 'Nigeria', 'Norway', 'Pakistan', 'Peru', 'Philippines', 'Poland', 'Portugal', 'Qatar',\n",
    "  'Romania', 'Russia', 'Serbia', 'Singapore', 'Slovakia', 'Slovenia', 'South Africa', 'South Korea', 'Spain', 'Sri Lanka', 'Switzerland', 'Taiwan', 'Thailand', 'Turkey', 'Uganda', 'Ukraine',\n",
    "   'United Kingdom', 'United States', 'Vietnam']\n",
    "\n",
    "shortlisted_countries = ['United Kingdom', 'United States',\"Japan\",\"China\",\"Canada\",\"France\",\"Germany\",\"Singapore\",\"Hong\",\"South Korea\", \"Australia\" ]\n",
    "#uncomment  del Argentina\n",
    "\n",
    "#C-G\n",
    "\n",
    "#print(countryNames)\n",
    "os.chdir(main_path)\n",
    "os.chdir(input_path_treasury)\n",
    "editedcountryNames = []\n",
    "for i in countryNames:\n",
    "  x = i\n",
    "  if \" Year\" in i:\n",
    "    # print(i)\n",
    "    x = i.replace(\" Year\",\"-Year\")\n",
    "    os.rename(r'{0}'.format(i),r'{0}'.format(x))\n",
    "\n",
    "    # print(x)\n",
    "  if \" Month\" in i:\n",
    "    # print(i)\n",
    "    x = i.replace(\" Month\",\"-Month\")\n",
    "    os.rename(r'{0}'.format(i),r'{0}'.format(x))\n",
    "\n",
    "  if \" (3).csv\" in i:\n",
    "    # print(i)\n",
    "    x = i.replace(\" (3).csv\",\".csv\")\n",
    "    os.rename(r'{0}'.format(i),r'{0}'.format(x))\n",
    "\n",
    "  editedcountryNames.append(x)\n",
    "os.chdir(main_path)\n",
    "\n",
    "# print(editedcountryNames)\n",
    "  \n",
    "\n",
    "dd = {}\n",
    "for name in countries:\n",
    "    tempCont = []\n",
    "    for country in editedcountryNames: #countryNames\n",
    "        if name in country:\n",
    "            tempCont.append(country)\n",
    "            \n",
    "    dd[name] = tempCont\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sorted(dd.items(), key=lambda x: x[0], reverse=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(main_path)\n",
    "os.chdir(output_path)\n",
    "doneBCont = glob.glob('*.{}'.format(xlsx_extension))\n",
    "doneBCont = [i.replace(\".xlsx\",\"\") for i in doneBCont]\n",
    "\n",
    "\n",
    "os.chdir(main_path)\n",
    "os.chdir(input_path_treasury)\n",
    "\n",
    "#------------\n",
    "\n",
    "# a func for  start\n",
    "\n",
    "# a func for renaming and creating a copy \n",
    "# Will do later on \n",
    "#-------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#-------------\n",
    "\n",
    "counter = 0\n",
    "for key in dd:\n",
    "  \n",
    "  #Uncomment\n",
    "  if key in doneBCont:\n",
    "    continue\n",
    "\n",
    "  \n",
    "\n",
    "  #Testing\n",
    "  # if key == \"Austria\":\n",
    "  #   exit()\n",
    "  # if key not in shortlisted_countries:\n",
    "  #   continue\n",
    "  # if key != \"United States\":\n",
    "  #   continue\n",
    "  # counter+=1\n",
    "  # if counter >= len(countryNames)/8:\n",
    "  #   break\n",
    "  \n",
    "\n",
    "  #Change Here\n",
    "  def mykey(value):\n",
    "    if \"Overnight\" in value:\n",
    "      ls= \"0-Aqwr\"\n",
    "    elif \"(1)\" in value or \"(2)\" in value:\n",
    "      ls = value.split(\" \")[-6]\n",
    "    \n",
    "      \n",
    "    else:\n",
    "      ls = value.split(\" \")[-5]\n",
    "    try:\n",
    "      ia = ls.split(\"-\")[1][0]\n",
    "    except:\n",
    "      print(value,\"Out Of Range\")\n",
    "      #Uncomment\n",
    "      # exit()\n",
    "    return ia\n",
    "  \n",
    "  \n",
    "  print(len(dd[key]))\n",
    "  print(\"before\",dd[key])\n",
    "  dd[key].sort(key=natural_keys)\n",
    "  \n",
    "  dd[key].sort(key=mykey)\n",
    "  print(\"after\",dd[key])\n",
    "  \n",
    " \n",
    "\n",
    "  \n",
    "  \n",
    "\n",
    "  print(\"Working for {0} bonds\".format(key))\n",
    "  print(\"All Directories\\n\", dd[key])\n",
    "\n",
    "  \n",
    "  #Change Here\n",
    "  leng = len(dd[key])//3   #//2\n",
    "  count = 0\n",
    "  nbonds=[]\n",
    "  c = 1\n",
    "  prev = numpy.array([])\n",
    "  for i in range(0,leng):\n",
    "    print(os.getcwd())\n",
    "    print(dd[key][count])\n",
    "    print(dd[key][count+1])\n",
    "    print(dd[key][count+2],\"loop\")\n",
    "    os.chdir(main_path)\n",
    "    os.chdir(input_path_treasury)\n",
    "\n",
    "    # print(dd[key][count],dd[key][count+1],dd[key][count+2])\n",
    "    # exit()\n",
    "    try:\n",
    "      #Change Here\n",
    "      read2010 = pd.read_csv(dd[key][count])\n",
    "      read1970 = pd.read_csv(dd[key][count+2])\n",
    "      read2000 = pd.read_csv(dd[key][count+1])\n",
    "\n",
    "      read2010l = [float(i[:-1].replace(\",\",\"\")) for i in read2010[\"Change %\"]]\n",
    "      read2010[\"Change %\"] = pd.DataFrame(read2010l, columns=[\"Change %\"])\n",
    "\n",
    "\n",
    "      read1970l = [float(i[:-1].replace(\",\",\"\")) for i in read1970[\"Change %\"]]\n",
    "      read1970[\"Change %\"] = pd.DataFrame(read1970l, columns=[\"Change %\"])\n",
    "\n",
    "      read2000l = [float(i[:-1].replace(\",\",\"\")) for i in read2000[\"Change %\"]]\n",
    "      read2000[\"Change %\"] = pd.DataFrame(read2000l, columns=[\"Change %\"])\n",
    "  \n",
    "      frames = [ read2010,read1970]\n",
    "      framee = pd.concat(frames)\n",
    "      #print(framee,\"...\")\n",
    "\n",
    "      \n",
    "\n",
    "      nbonds.append(pd.concat([framee,read2000]))\n",
    "      # print(nbonds,\"]]]]]]]]]]]]]\")\n",
    "\n",
    "      \n",
    "      \n",
    "   \n",
    "    except:\n",
    "      read1970 = pd.read_csv(dd[key][count+1])\n",
    "      read1970l = [float(i[:-1].replace(\",\",\"\")) for i in read1970[\"Change %\"]]\n",
    "      read1970[\"Change %\"] = pd.DataFrame(read1970l, columns=[\"Change %\"])\n",
    "\n",
    "      \n",
    "      nbonds.append(read1970)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    count+=3\n",
    "    c+=1\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "  \n",
    "  print(\"Merging\")\n",
    "  #print(nbonds)\n",
    "  #exit()\n",
    "  \n",
    "  \n",
    "\n",
    "  bonds = []\n",
    "  for i in range(0,len(nbonds)):\n",
    "\n",
    "    nbonds[i] = nbonds[i].set_index(\"Date\")\n",
    "    nbonds[i] = nbonds[i].apply(lambda x: pd.to_numeric(x.astype(str).str.replace(',','')))\n",
    "    bonds.append(nbonds[i])\n",
    "\n",
    "  print(len(bonds))\n",
    "  \n",
    "\n",
    "  \n",
    "  # print(bonds)\n",
    "  print(\"-------------------------------------------\\n------------------------\")\n",
    " \n",
    "  ####################TEST FIELD###################\n",
    "  \n",
    "  parent_newBonds = []\n",
    "\n",
    "  count = 1\n",
    "  for x in range(0,len(bonds)-1):\n",
    "    # print(\"Main Loop\")\n",
    "    newBonds = []\n",
    "    for i in range(count,len(bonds)):\n",
    "      \n",
    "      # print(\"Inside Loop\")\n",
    "      # print(x , i)\n",
    "\n",
    "      #Process\n",
    "      xf = bonds[i].sub(bonds[x])\n",
    "      xf = xf[~xf.index.duplicated()]\n",
    "      xf = xf.fillna(value=\"na\")\n",
    "      newBonds.append(xf)\n",
    "    \n",
    "    parent_newBonds.append(newBonds)\n",
    "    \n",
    "    count += 1\n",
    "  #print(parent_newBonds)\n",
    "\n",
    "\n",
    "  resulx,sortex_df = extractingTreasuryYeilds(nbonds)\n",
    "  writer = StyleFrame.ExcelWriter('{0}.xlsx'.format(key))\n",
    "  writerRenamed = StyleFrame.ExcelWriter('{0}.xlsx'.format(key))\n",
    "\n",
    "  if key in shortlisted_countries:\n",
    "    shortlist_sortex_df = shortlistedYeild(resulx)\n",
    "    writerShorlisted = StyleFrame.ExcelWriter('{0}.xlsx'.format(key))\n",
    "    writerShortlistedRenamed = StyleFrame.ExcelWriter('{0}.xlsx'.format(key))\n",
    "\n",
    "    mod_date_sortex_df, price_resulx,date_sortex_df = quarterlyInsightsYeild(resulx, resulx,0)\n",
    "    imputed_yeild_df = ImputedYeild(mod_date_sortex_df)\n",
    "\n",
    "    \n",
    "    writerImputed = StyleFrame.ExcelWriter('{0}.xlsx'.format(key))\n",
    "    writerQuarterly = StyleFrame.ExcelWriter('{0}.xlsx'.format(key))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "  aso = 0\n",
    "  inc = 0\n",
    "  for bonds in parent_newBonds:\n",
    "\n",
    "    result,sorted_df = extractingTreasurySpreads(bonds,aso) #inc\n",
    "    copy_sortex_df,copy_sorted_df = globalRename(sortex_df,sorted_df, aso)\n",
    "\n",
    "    \n",
    "    addTYSheet(writer,sortex_df)\n",
    "    addTSSheet(writer,sorted_df,aso)\n",
    "\n",
    "\n",
    "    #Renamed\n",
    "    addTYSheet(writerRenamed,copy_sortex_df)\n",
    "    addTSSheet(writerRenamed,copy_sorted_df,aso)\n",
    "    \n",
    "    if key in shortlisted_countries: #not remo uncomment\n",
    "      shortlist_sorted_df = shortlistedSpread(result)\n",
    "      copy_shortlist_sortex_df,copy_shortlist_sorted_df = globalRename(shortlist_sortex_df,shortlist_sorted_df,aso)\n",
    "\n",
    "      #Shortlisted\n",
    "      addTYSheet(writerShorlisted,shortlist_sortex_df)\n",
    "      addTSSheet(writerShorlisted,shortlist_sorted_df,aso)\n",
    "\n",
    "      #Shorlisted Renamed\n",
    "      addTYSheet(writerShortlistedRenamed,copy_shortlist_sortex_df)\n",
    "      addTSSheet(writerShortlistedRenamed,copy_shortlist_sorted_df,aso)\n",
    "\n",
    "      #Quarterly Insights\n",
    "      mod_date_sorted_df = quarterlyInsightsSpread(result, price_resulx,date_sortex_df, aso)\n",
    "      addTYSheet(writerQuarterly,mod_date_sortex_df)\n",
    "      mod_date_sorted_dff = mod_date_sorted_df.replace(\"nan\",\"na\")\n",
    "      addTSSheet(writerQuarterly,mod_date_sorted_dff,aso)\n",
    "\n",
    "      #Imputed Quarterly\n",
    "\n",
    "      final_spread_imputed_quartely = ImputedSpread(imputed_yeild_df, mod_date_sorted_df,aso)\n",
    "      addTYSheet(writerImputed,imputed_yeild_df)\n",
    "      addTSSheet(writerImputed,final_spread_imputed_quartely,aso)\n",
    "\n",
    "     \n",
    "\n",
    "      \n",
    "\n",
    "    aso +=1\n",
    "    inc += 2\n",
    "  \n",
    "  print(\"Writing Normal Files\")\n",
    "  os.chdir(main_path)\n",
    "  os.chdir(output_path)\n",
    "  writer.save()\n",
    "  os.chdir(main_path)\n",
    "\n",
    "  os.chdir(production_ouput_path)\n",
    "  writerRenamed.save()\n",
    "  os.chdir(main_path)\n",
    "\n",
    "  if key in shortlisted_countries:\n",
    "    print(\"Writing Shortlisted File\", key)\n",
    "  \n",
    "    os.chdir(main_path)\n",
    "    os.chdir(shortlist_output_path)\n",
    "    writerShorlisted.save()\n",
    "    os.chdir(main_path)\n",
    "\n",
    "    os.chdir(shortlist_production_ouput_path)\n",
    "    writerShortlistedRenamed.save()\n",
    "    os.chdir(main_path)\n",
    "\n",
    "    print(\"Writing Quarterly\", key)\n",
    "\n",
    "    os.chdir(quarterly_path)\n",
    "    writerQuarterly.save()\n",
    "    os.chdir(main_path)\n",
    "\n",
    "    print(\"Writing Imputed Quarterly\", key)\n",
    "\n",
    "    os.chdir(imputed_quarterly_path)\n",
    "    writerImputed.save()\n",
    "    os.chdir(main_path)\n",
    "\n",
    "\n",
    "  os.chdir(main_path)\n",
    "  os.chdir(production_ouput_path)\n",
    "  writeToCsv(dataDictd,\"dataDictTreasurySpreads.csv\")\n",
    "  writeToCsv(dataDictx, \"dataDictTreasuryYields.csv\")\n",
    "  os.chdir(main_path)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "# exit()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
